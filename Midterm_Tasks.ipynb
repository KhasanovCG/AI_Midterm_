{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMxBvxRbpRi+e1GOE7bsEZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhasanovCG/AI_Midterm_/blob/main/Midterm_Tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK-1"
      ],
      "metadata": {
        "id": "RgPj3zgSik_E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bY-oPATnuIFF"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "def generate_sequential_data(num_sequences, sequence_length, failure_probability):\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_sequences):\n",
        "        sequence = []\n",
        "\n",
        "        for _ in range(sequence_length):\n",
        "            temperature = random.uniform(50, 100)\n",
        "            vibration = random.uniform(0, 1)\n",
        "            belt_speed = random.uniform(0.5, 2.0)\n",
        "\n",
        "            sequence.append([temperature, vibration, belt_speed])\n",
        "\n",
        "        data.append(sequence)\n",
        "\n",
        "    return np.array(data)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sequential_data(num_sequences, sequence_length, failure_probability):\n",
        "    data = []\n",
        "\n",
        "    for _ in range(num_sequences):\n",
        "        sequence = []\n",
        "\n",
        "        for _ in range(sequence_length):\n",
        "            temperature = random.uniform(50, 100)\n",
        "            vibration = random.uniform(0, 1)\n",
        "            belt_speed = random.uniform(0.5, 2.0)\n",
        "\n",
        "            # Introduce a failure event based on probability\n",
        "            if random.random() < failure_probability:\n",
        "                temperature += random.uniform(10, 20)\n",
        "                vibration += random.uniform(0.5, 1.0)\n",
        "                belt_speed -= random.uniform(0.2, 0.5)\n",
        "\n",
        "            sequence.append([temperature, vibration, belt_speed])\n",
        "\n",
        "        data.append(sequence)\n",
        "\n",
        "    return np.array(data)\n"
      ],
      "metadata": {
        "id": "c4YLWGt5uWm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_sequences = 100\n",
        "sequence_length = 50\n",
        "\n",
        "\n",
        "# Generate datasets with different failure probabilities\n",
        "data_low_failure = generate_sequential_data(num_sequences, sequence_length, 0.1)\n",
        "data_high_failure = generate_sequential_data(num_sequences, sequence_length, 0.2)\n",
        "\n",
        "# Save datasets to files\n",
        "np.save('data_low_failure.npy', data_low_failure)\n",
        "np.save('data_high_failure.npy', data_high_failure)\n"
      ],
      "metadata": {
        "id": "XyyHc3BeuZ_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK-2\n"
      ],
      "metadata": {
        "id": "g7Pq6f776njb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have already generated data and saved it in NumPy arrays\n",
        "# Load the generated data\n",
        "data_low_failure = np.load('data_low_failure.npy')\n",
        "data_high_failure = np.load('data_high_failure.npy')\n",
        "\n",
        "def preprocess_sequential_data(data):\n",
        "    # Flatten the data sequences\n",
        "    flattened_data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "    # Extract the features (sensor readings) and labels (failure or non-failure)\n",
        "    features = flattened_data[:, :-1]  # All columns except the last one (failure)\n",
        "    labels = flattened_data[:, -1]  # The last column (failure)\n",
        "\n",
        "    # Scale the features using StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(features)\n",
        "\n",
        "    return scaled_features, labels\n",
        "\n",
        "# Preprocess the data for both low and high failure probability datasets\n",
        "low_failure_features, low_failure_labels = preprocess_sequential_data(data_low_failure)\n",
        "high_failure_features, high_failure_labels = preprocess_sequential_data(data_high_failure)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# Adjust test_size and random_state as needed\n",
        "low_failure_X_train, low_failure_X_test, low_failure_y_train, low_failure_y_test = train_test_split(\n",
        "    low_failure_features, low_failure_labels, test_size=0.2, random_state=42)\n",
        "\n",
        "high_failure_X_train, high_failure_X_test, high_failure_y_train, high_failure_y_test = train_test_split(\n",
        "    high_failure_features, high_failure_labels, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "OKfdobb76rIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK-3\n"
      ],
      "metadata": {
        "id": "znhPk6Td81Fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define a function to create the LSTM model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = keras.Sequential()\n",
        "    model.add(keras.layers.LSTM(units=64, input_shape=input_shape, return_sequences=True))\n",
        "    model.add(keras.layers.LSTM(units=64))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Specify the input shape based on your data\n",
        "# For example, if each sequence has 50 time steps and 3 features per time step\n",
        "input_shape = (50, 3)\n",
        "\n",
        "# Create the LSTM model\n",
        "lstm_model = create_lstm_model(input_shape)\n"
      ],
      "metadata": {
        "id": "RQSGxGoR8373"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c\n",
        "# Compile the model\n",
        "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "rahg7ZK38_Ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK-4"
      ],
      "metadata": {
        "id": "qDXYRsC99SuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Generate placeholder data\n",
        "# You can replace this with your actual data\n",
        "num_samples = 80\n",
        "sequence_length = 50\n",
        "num_features = 3  # You can adjust this based on your data\n",
        "\n",
        "# Generate random data for training and testing\n",
        "low_failure_X_train = np.random.rand(num_samples, sequence_length, num_features)\n",
        "low_failure_y_train = np.random.randint(2, size=num_samples)  # Binary labels (0 or 1)\n",
        "\n",
        "low_failure_X_test = np.random.rand(num_samples, sequence_length, num_features)\n",
        "low_failure_y_test = np.random.randint(2, size=num_samples)\n",
        "\n",
        "# Create an LSTM model (you can replace this with your actual model)\n",
        "lstm_model = keras.Sequential([\n",
        "    keras.layers.LSTM(64, input_shape=(sequence_length, num_features)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "lstm_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Task 4a: Train the LSTM model using the training data\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "\n",
        "# Train the model\n",
        "history = lstm_model.fit(\n",
        "    low_failure_X_train,\n",
        "    low_failure_y_train,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(low_failure_X_test, low_failure_y_test)\n",
        ")\n",
        "\n",
        "# Task 4c: Monitor the training process and evaluate the model's performance\n",
        "# Access training history\n",
        "training_loss = history.history['loss']\n",
        "training_accuracy = history.history['accuracy']\n",
        "validation_loss = history.history['val_loss']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = lstm_model.evaluate(low_failure_X_test, low_failure_y_test)\n",
        "\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSLEVRJFQjsa",
        "outputId": "0e66c1c3-c8da-427a-826a-3678ba88520a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 3s 328ms/step - loss: 0.7063 - accuracy: 0.4750 - val_loss: 0.7054 - val_accuracy: 0.4375\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6980 - accuracy: 0.4750 - val_loss: 0.6974 - val_accuracy: 0.4625\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.6964 - accuracy: 0.4125 - val_loss: 0.6910 - val_accuracy: 0.5625\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.6936 - accuracy: 0.5125 - val_loss: 0.6881 - val_accuracy: 0.5625\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.6925 - accuracy: 0.5250 - val_loss: 0.6869 - val_accuracy: 0.5625\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.6930 - accuracy: 0.5250 - val_loss: 0.6862 - val_accuracy: 0.5625\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.6931 - accuracy: 0.5250 - val_loss: 0.6862 - val_accuracy: 0.5625\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6930 - accuracy: 0.5250 - val_loss: 0.6867 - val_accuracy: 0.5625\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.6924 - accuracy: 0.5250 - val_loss: 0.6870 - val_accuracy: 0.5625\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6920 - accuracy: 0.5250 - val_loss: 0.6870 - val_accuracy: 0.5625\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.6918 - accuracy: 0.5250 - val_loss: 0.6872 - val_accuracy: 0.5625\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.6916 - accuracy: 0.5250 - val_loss: 0.6878 - val_accuracy: 0.5625\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.6916 - accuracy: 0.5250 - val_loss: 0.6883 - val_accuracy: 0.5625\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.6911 - accuracy: 0.5250 - val_loss: 0.6885 - val_accuracy: 0.5625\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6910 - accuracy: 0.5250 - val_loss: 0.6888 - val_accuracy: 0.5625\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6909 - accuracy: 0.5250 - val_loss: 0.6888 - val_accuracy: 0.5625\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.6907 - accuracy: 0.5250 - val_loss: 0.6886 - val_accuracy: 0.5625\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6904 - accuracy: 0.5250 - val_loss: 0.6887 - val_accuracy: 0.5625\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.6905 - accuracy: 0.5250 - val_loss: 0.6893 - val_accuracy: 0.5625\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.6907 - accuracy: 0.5250 - val_loss: 0.6895 - val_accuracy: 0.5625\n",
            "3/3 [==============================] - 0s 10ms/step - loss: 0.6895 - accuracy: 0.5625\n",
            "Test Loss: 0.6895250678062439\n",
            "Test Accuracy: 0.5625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK-5"
      ],
      "metadata": {
        "id": "d7Cbw0DDQ7XA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "import threading\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# Function to generate and process data\n",
        "def generate_data():\n",
        "    while True:\n",
        "        # Generate a new data point for temperature, vibration, and belt speed\n",
        "        new_data_point = np.random.rand(3)  # Replace with your data generation logic\n",
        "\n",
        "        # Append the new data point to a data buffer for prediction\n",
        "        data_buffer.append(new_data_point)\n",
        "\n",
        "        # Implement your alerting logic here if a failure is predicted\n",
        "\n",
        "        # Sleep for the specified interval (e.g., 5 seconds)\n",
        "        time.sleep(5)\n",
        "\n",
        "# Initialize data buffer\n",
        "data_buffer = []\n",
        "\n",
        "# Create a thread to generate data\n",
        "data_generation_thread = threading.Thread(target=generate_data)\n",
        "\n",
        "# Start the data generation thread\n",
        "data_generation_thread.start()\n",
        "\n",
        "# You can perform other tasks here concurrently\n",
        "\n",
        "# Keep the main program running\n",
        "try:\n",
        "    while True:\n",
        "        pass\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Data generation stopped by user.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kqe1pDghWUmR",
        "outputId": "564ac21d-a54d-4786-ad9a-fcbc274ab29e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data generation stopped by user.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#b\n",
        "# Function to generate and process data\n",
        "def generate_data():\n",
        "    while True:\n",
        "        # Generate a new data point for temperature, vibration, and belt speed\n",
        "        new_data_point = np.random.rand(3)  # Replace with your data generation logic\n",
        "\n",
        "        # Append the new data point to a data buffer for prediction\n",
        "        data_buffer.append(new_data_point)\n",
        "\n",
        "        # Implement your alerting logic here if a failure is predicted\n",
        "\n",
        "        # Sleep for the specified interval (e.g., 5 seconds)\n",
        "        time.sleep(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "nMM2DtIhWY4A"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c\n",
        "# Initialize prediction with a default value\n",
        "prediction = 0.0  # You can choose an appropriate default value\n",
        "# Define the threshold value for predicting failures\n",
        "threshold = 0.5  # You can adjust this value as needed\n",
        "\n",
        "# Make predictions using the model\n",
        "if len(data_buffer) >= sequence_length:\n",
        "    # Extract the last 'sequence_length' data points\n",
        "    input_data = np.array(data_buffer[-sequence_length:])\n",
        "\n",
        "    # Reshape the input data to match the model's input shape\n",
        "    input_data = input_data.reshape(1, sequence_length, num_features)\n",
        "\n",
        "    # Use the model to make predictions\n",
        "    prediction = lstm_model.predict(input_data)\n",
        "\n",
        "    # You can define a threshold for predicting failures\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmWkVnJhbx1v",
        "outputId": "9f68e96d-a275-4fd9-bea4-bb8014f5deae"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ]
    }
  ]
}